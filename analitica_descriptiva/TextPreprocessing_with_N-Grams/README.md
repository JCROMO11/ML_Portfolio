# Text Preprocessing with N-Grams

## Overview
This project processes textual data by generating n-grams (sequences of "n" consecutive characters) from the input text. It cleans and transforms the text into a simplified form for further analysis or machine learning tasks. The process involves:

- Loading input data: Reads the input text data from a file.
- Text cleaning: Removes unwanted characters, punctuation, and normalizes the text.
- N-gram generation: Converts text into n-grams (based on the user-defined "n" parameter).
- Mapping duplicates: Creates a cleaned version of the text by resolving duplicates in the n-grams.
- Saving output data: Outputs the cleaned and processed text into a new file.

## Key Concepts
N-grams:
An n-gram is a sequence of "n" consecutive characters extracted from a string of text. For example:

- A 2-gram (bigram) for the word "hello" would be: ["he", "el", "ll", "lo"]
- A 3-gram (trigram) for the same word would be: ["hel", "ell", "llo"]
These n-grams can be used in various NLP tasks like text analysis, feature extraction, and classification.

## Workflow:
- 'Input File': Text data from a file is read and loaded into a pandas DataFrame.
- Text Cleaning: The text is cleaned by:
- Stripping extra spaces.
- Converting to lowercase.
- Removing special characters and punctuation.
- N-gram Creation: The text is transformed into a list of n-grams of size n, where n can be specified (default is 2 for bigrams).
- Cleaned Column: The cleaned version of the text is generated by eliminating duplicates in the n-grams.
- Output File: The processed text is saved to an output file.
